## Hello There 👋

 I'm Sudiptho

🎯 **Data Engineer | Python Developer | Cloud & ETL Specialist**

Welcome to my GitHub! I'm a data engineer with close to 6 years of experience designing and optimizing scalable data pipelines, performing advanced data analysis, and integrating cloud-based solutions across AWS, Azure, and GCP. I enjoy solving real-world problems with code, data, and clean architecture.

---

## 💼 What I Do

- 🔄 Build robust, automated **ETL pipelines** using Python, SQL, and Apache Airflow
- ☁️ Develop cloud-native data solutions on **AWS, Azure, and GCP**
- 📊 Create meaningful dashboards using **Power BI, Tableau, and Looker**
- 🧠 Work on fraud analytics, risk data, and business intelligence at scale
- 🛠 Write clean, testable, production-ready code with CI/CD best practices

---

## 🚀 Featured Projects

| Project | Description | Tech |
|--------|-------------|------|
| [AWS Customer Concessions Pipeline](https://github.com/Sudeep8084/Data-Engineer-Portfolio) | Production-grade data pipeline for compliance and BI reporting | Python, AWS, Snowflake |
| [GCP & Azure ETL Migration](https://github.com/sudiptho/gcp_azure_etl_migration) | Migration of legacy ETL pipelines to cloud-native platforms improving speed and reliability. | PySpark, Hive, GCP (BigQuery, Dataflow), Azure (ADF, Synapse) |
| [Data Quality Monitoring Framework](https://github.com/sudiptho/data_quality_monitoring) | Modular framework to embed validation and alerting in data pipelines. | Python, SQL, Airflow, Power BI, Snowflake |


---

## 🛠️ Tech Stack

**Languages**: Python, SQL, HiveQL, Scala  
**Cloud**: AWS (S3, Redshift), GCP (BigQuery), Azure (Data Lake, Synapse)  
**Data Tools**: Apache Airflow, dbt, Spark, Kafka, Snowflake, Informatica  
**BI**: Power BI, Tableau, Domo  
**Other**: Git, Docker, Jenkins, Kubernetes, REST APIs  

---

Let's connect and build something great together!
📍 Parsippany, New Jersey 
---

-->
